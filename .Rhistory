axis.title=element_text(size=12),axis.text = element_text(size=12),
plot.title = element_text(hjust = 0.5,size=12,face="italic"))+
ggtitle("Performance of ER Varies Across \n enacted plan (dashed lines) and \n simulated plans (histograms)")
0.55+0.5423+0.6375+0.675+0.725+0.75
3.8798/6
0.75+0.875+0.6875+0.875+0.625+0.75
4.5625/6
3.8798*5
10/16
0.375+0.625
3.625/5
4-3.625
#SY 08/16/2024
rm(list=ls())
gc()
library(Hmisc)
library(dplyr)
library(data.table)
library(sf)
library(redist)
# Install and load the Rcpp package if you haven't already
# install.packages("Rcpp")
library(Rcpp)
#set working directories
main_dir = "C:\\Users\\Sidak Yntiso\\Dropbox\\RPV\\Code\\Simulation\\Simulating Districts\\"
recom_dir = paste(main_dir,"ReCom Plans for NY\\Output Data\\",sep="")
list.files(recom_dir)
#store vote share vectors from each simulated plan in a list
recom_districts_NY=data.frame()
#load
recom_nv_files = grep("nv_df_NewYork_neutral_run",list.files(path = recom_dir,recursive = T),value = T)
recom_sim_files = grep("store_plans_NewYork_neutral_run",list.files(path = recom_dir,recursive = T),value = T)
recom_districts_NY <- read.csv(paste(recom_dir,recom_sim_files[1],sep = "")) #load the simulations
#reshape from wide to long
recom_districts_NY <- melt(setDT(recom_districts_NY),
id.vars = c("Index","GEOID"), variable.name = "Map",
value.name = "CD")
describe(recom_districts_NY$Map)
#correct map labels
recom_districts_NY$Map=gsub("Map","",recom_districts_NY$Map)
recom_districts_NY$Map= as.numeric(as.factor(recom_districts_NY$Map))
num_plans = max(recom_districts_NY$Map)
main_dir
gc()
for(i in 2:length(recom_sim_files)){
gc()
print(i)
sim_wide = read.csv(paste(recom_dir,recom_sim_files[i],sep = "")) #load the simulations
#reshape from wide to long
sim_long <- melt(setDT(sim_wide),
id.vars = c("Index","GEOID"), variable.name = "Map",
value.name = "CD")
#correct map labels
sim_long$Map=gsub("Map","",sim_long$Map)
sim_long$Map= as.numeric(as.factor(sim_long$Map))
sim_long$Map = sim_long$Map +num_plans
num_plans = max(sim_long$Map)
#save
recom_districts_NY <- plyr::rbind.fill(recom_districts_NY,sim_long)
rm(sim_wide,sim_long)
}
gc()
View(recom_districts_NY)
gc()
head(recom_districts_NY)
nrow(recom_districts_NY)/50000
save(recom_districts_NY,file=paste(main_dir,"ny_50k_recom_sims.RDA"))
rm(list=ls())
gc()
library(Hmisc)
#Created: 07/18/2024
#Last Edited: 08/13/2024
#-----------------------------------------------------------#
#Load Data
#-----------------------------------------------------------#
main_dir = "C:\\Users\\Sidak Yntiso\\Dropbox\\Simpson_Yntiso\\"
FY2013 <- haven::read_dta(paste(main_dir,"FY2013_2023.dta",sep=""))
#Sentencing Commission Data (see /SG Records FY2013-FY2023 (H Simpson - Texas A&M) 03-27-2024.xlsx)
page_VSC_data <- haven::read_dta(paste(main_dir,"page_2015_2017.dta",sep=""))
table(page_VSC_data $FiscalYr)
page_VSC_data$offense.y = substr(page_VSC_data$Off1Date,7,10)
page_VSC_data$offense.m = substr(page_VSC_data$Off1Date,1,3)
page_VSC_data$offense.d = substr(page_VSC_data$Off1Date,4,6)
page_VSC_data$offense.m <- gsub("/","",page_VSC_data$offense.m,perl = T)
page_VSC_data$offense.d <- gsub("/","",page_VSC_data$offense.d,perl = T)
page_VSC_data$offense.m= trimws(page_VSC_data$offense.m)
page_VSC_data$offense.m= stringr::str_pad(page_VSC_data$offense.m,side="left",width=2,pad="0")
page_VSC_data$x <- paste(page_VSC_data$DefLastName,page_VSC_data$DefFirstName,
page_VSC_data$offense.y,page_VSC_data$offense.m,sep = "_")
describe(page_VSC_data$x)
#Court data
circuit_court_data <- haven::read_dta(
paste(main_dir,"VA/Virginia data/Clean Data/Data/va_circuit_courts.dta",sep =""))
page_court_full =subset(circuit_court_data,District=="PAGE COUNTY")
page_court_cal = subset(page_court_full,as.Date(disposition_date,format="%Y-%m-%d")>
as.Date("07/01/2014",format="%m/%d/%Y"))
page_court_cal = subset(page_court_cal,as.Date(disposition_date,format="%Y-%m-%d")<
as.Date("07/01/2018",format="%m/%d/%Y"))
page_court_cal$offense.y = substr(page_court_cal$OffenseDate,1,4)
page_court_cal$offense.m = substr(page_court_cal$OffenseDate,6,7)
page_court_cal$offense.d = substr(page_court_cal$OffenseDate,9,10)
page_court_cal$x <- paste(page_court_cal$last_name,page_court_cal$first_name,
page_court_cal$offense.y,page_court_cal$offense.m,sep = "_")
page_court_data  = subset(page_court_cal,felony==1&prob_vio==0& conviction==1)
page_court_data  = subset(page_court_data,is.na(convict_case_severity)|
convict_case_severity >365.25)
0.609+0.7215+0.75+0.7875
2.868/4
load("C:/Users/Sidak Yntiso/Dropbox/Simpson_Yntiso/VA/Virginia data/Clean Data/Data/Matching Voter File/va_circuit_courts_voters.RDA")
View(va_courts_final)
describe(va_courts_final$exact_likely_dem)
library(Hmisc)
describe(va_courts_final$exact_likely_dem)
describe(va_courts_final$exact_likely_dem[va_courts_final$year==2016])
describe(va_courts_final$exact_likely_dem[!va_courts_final$year==2016])
describe(va_courts_final$exact_likely_dem[!va_courts_final$year==2016&!va_courts_final$disp_year==2016])
describe(va_courts_final$exact_voter_regdate)
gc()
q()
load(paste(main_dir,"\\Processed Data\\suffolk_pd_exams.RDA",sep = ""))
#SY
#08/20/2024
# Collecting SCPD exam data
rm(list=ls())
gc()
library(pdftools)
library(readr)
library(dplyr)
library(stringr)
library(Hmisc)
library('humaniformat')  #Parse first name, last name in exam data
trim <- function(x){gsub("^\\s+|\\s+$", "", x)} ## get rid of leading and trailing spaces
main_dir="C:\\Users\\Sidak Yntiso\\Dropbox\\Simpson_Yntiso\\Exams\\Data\\Suffolk PD\\"
load(paste(main_dir,"\\Processed Data\\suffolk_pd_exams.RDA",sep = ""))
summary(lm(hired~lottery_num,data=suffolk_2015))
summary(lm(hired~lottery_num,data=suffolk_2015))
load(paste(main_dir,"\\Processed Data\\suffolk_pd_exams_payroll.RDA",sep = ""))
summary(lm(hired~lottery_num,data=suffolk_2015))
suffolk_2015$lottery_norm =
(suffolk_2015$lottery_num-min(suffolk_2015$lottery_num,na.rm = T))/
(max(suffolk_2015$lottery_num)-min(suffolk_2015$lottery_num,na.rm = T))
describe(suffolk_2015$lottery_norm)
suffolk_2015$lottery_norm =
(suffolk_2015$lottery_num-min(suffolk_2015$lottery_num,na.rm = T))/
(max(suffolk_2015$lottery_num,na.rm = T)-min(suffolk_2015$lottery_num,na.rm = T))
suffolk_2015$lottery_norm[suffolk_2015$lottery_num==1]
describe(suffolk_2015$lottery_norm[suffolk_2015$lottery_num==1])
suffolk_2015$lottery_norm[is.na(suffolk_2015$lottery_num)]
describe(suffolk_2015$lottery_norm[is.na(suffolk_2015$lottery_num)])
summary(lm(hired~lottery_norm,data=suffolk_2015))
plot(suffolk_2015$lottery_norm,suffolk_2015$lottery_num)
suffolk_2015$lottery_norm =
(max(suffolk_2015$lottery_num,na.rm = T)-suffolk_2015$lottery_num)/
(max(suffolk_2015$lottery_num,na.rm = T)-min(suffolk_2015$lottery_num,na.rm = T))
plot(suffolk_2015$lottery_norm,suffolk_2015$lottery_num)
summary(lm(hired~lottery_norm,data=suffolk_2015))
suffolk_2019$lottery_norm =
(max(suffolk_2019$lottery_num,na.rm = T)-suffolk_2019$lottery_num)/
(max(suffolk_2019$lottery_num,na.rm = T)-min(suffolk_2019$lottery_num,na.rm = T))
describe(suffolk_2019$lottery_num)
class(suffolk_2019$lottery_num)
suffolk_2019$lottery_num=as.numeric(suffolk_2019$lottery_num)
suffolk_2019$lottery_norm =
(max(suffolk_2019$lottery_num,na.rm = T)-suffolk_2019$lottery_num)/
(max(suffolk_2019$lottery_num,na.rm = T)-min(suffolk_2019$lottery_num,na.rm = T))
summary(lm(hired~lottery_norm,data=suffolk_2019))
summary(lm(hired~as.numeric(score>95),data=suffolk_2015))
summary(lm(hired~as.numeric(score>95),data=suffolk_2019))
summary(lm(hired~as.numeric(score>95),data=suffolk_2015))
summary(lm(hired~as.numeric(score>95),data=suffolk_2019))
summary(lm(hired~lottery_norm,data=suffolk_2015))
summary(lm(hired~as.numeric(score>95),data=suffolk_2015))
summary(lm(hired~lottery_norm,data=suffolk_2015))
install.packages("RDHonest")
library(RDHonest)
RDHonest(voteshare ~ margin, data = lee08, kern = "uniform", M = 0.1, h = 10)
data("lee08")
head('lee08')
View(lee08)
lee08$district = sample(1:5,nrow(lee08))
lee08$district = sample(1:5,nrow(lee08),replace = F)
lee08$district = sample(nrow(lee08),1:5,replace = F)
lee08$district = sample(c(1:5),nrow(lee08))
lee08$district = sample(c(1:5),nrow(lee08),replace = F)
sample(c(2:3),2)
sample(c(2:3),4)
sample(c(2:3),4,replace = T)
lee08$district = sample(c(1:5),nrow(lee08),replace = T)
RDHonest(voteshare ~ margin|district, data = lee08, kern = "uniform", M = 0.1, h = 10)
RDHonest(voteshare ~ margin|as.factor(district), data = lee08, kern = "uniform", M = 0.1, h = 10)
rm(list=ls())
library(Hmisc)
library(dplyr)
main_dir ="C:\\Users\\Sidak Yntiso\\Dropbox\\RPV\\Code\\Simulation\\Output\\new_states_shapefiles_and_CDs_10_14\\"
setwd(main_dir)
list.files()
state_6_precincts= read.csv("state_1_precincts.csv")
View(state_6_precincts)
sum(state_6_precincts$population*state_6_precincts$per_minority)
sum(state_6_precincts$population)
99171/1498014
# Clear working environment
rm(list = ls())
# Set working directory to correct Dropbox folder
setwd('~/Dropbox/RPV/Code/Simulation')
getwd()
gc()
rm(list=ls())
# Clear working environment
rm(list = ls())
# Set working directory to correct Dropbox folder
setwd('~/Dropbox/RPV/Code/Simulation')
# Clear working environment
rm(list = ls())
# Set working directory to correct Dropbox folder
setwd('C:/Users/Sidak Yntiso/Dropbox/RPV/Code/Simulation')
# Clear working environment
rm(list = ls())
# Set working directory to correct Dropbox folder
setwd('C:/Users/Sidak Yntiso/Dropbox/RPV/Code/Simulation')
# Load packages
library(truncnorm)
library(ipumsr)
library(patchwork)
library(furrr)
library(progressr)
library(Rcpp)
library(msm)
library(sf)
library(viridis)
require(haven)
require(LaplacesDemon)
require(arm)
require(fastDummies)
require(randomizr)
require(lme4)
require(mvtnorm)
require(data.table)
require(reshape2)
require(ei)
library(dbscan)
library(igraph)
library(spdep)
library(tidyverse)
#--------------
# SOURCE
# for seed distributions to simulate_voters()
source('../Analysis/empirical_distributions_race_by_census_block_tc.R')
View(read_CVAP_data)
simulate_voters = function(target_population = 1000000,
state_type = 'medium',
seed_distributions = emp_pop_min_joint_dists,
prob_minority_dem_vote = 0.9,
prob_majority_dem_vote = 0.45,
voting_prob_assignment = 'constant',
context_threshold = 0.2,
prob_shock_pos = 0.5,
shock_positive = 0.1,
prob_shock_neg = 0.5,
shock_negative = 0.2,
sd_ind_noise = 0.02,
sd_precinct_minority = 0.05,
sd_precinct_majority = 0.05) {
# # uncomment for debugging
# target_population = 1000000
# state_type = 'low' # sample(c('low', 'medium', 'high'), 1)
# seed_distributions = emp_pop_min_joint_dists
# prob_minority_dem_vote = 0.9
# prob_majority_dem_vote = 0.45
# voting_prob_assignment = sample(c('constant', 'precinct'), 1)
# sd_ind_noise = 0.02
# sd_precicnt_majority = 0.05
# sd_precinct_minority = 0.05
#########################################
### Step 1: Check arguments are valid ###
#########################################
if (!(state_type %in% c('low', 'medium', 'high'))) {
stop('Invalid argument for state_type')
}
if (!(voting_prob_assignment %in% c('constant', 'precinct', 'context'))) {
stop('Invalid argument for voting_prob_assignment')
}
# Validate parameters if 'context' is selected
if (voting_prob_assignment == 'context') {
if (!is.numeric(context_threshold) || context_threshold < 0 || context_threshold > 1) {
stop('context_threshold must be a numeric value between 0 and 1')
}
if (!is.numeric(prob_shock_pos) || prob_shock_pos < 0 || prob_shock_pos > 1) {
stop('prob_shock_pos must be a numeric value between 0 and 1')
}
if (!is.numeric(shock_positive) || shock_positive < 0 || shock_positive > 1) {
stop('shock_positive must be a numeric value between 0 and 1')
}
if (!is.numeric(prob_shock_neg) || prob_shock_neg < 0 || prob_shock_neg > 1) {
stop('prob_shock_neg must be a numeric value between 0 and 1')
}
if (!is.numeric(shock_negative) || shock_negative < 0 || shock_negative > 1) {
stop('shock_negative must be a numeric value between 0 and 1')
}
}
##################################################################################
### Step 2: Define target minority percentage and beta distribution parameters ###
##################################################################################
# Define seed states for each state_type
seed_states = list(
low = c('mt', 'or', 'ut', 'vt', 'wy'), # removed ca because 1 - WHT_CVAP means CA has high minority share even if low black share
medium = c('fl', 'il', 'mi', 'ny', 'pa', 'tx'),
high = c('al', 'ga', 'la', 'md', 'ms', 'sc')
)
# Select seed states for the given state_type
selected_seed_states = seed_states[[state_type]]
# Combine the precinct data from selected seed states
census_blocks = data.frame(
population = unlist(lapply(seed_distributions[selected_seed_states], function(df) df$population)),
per_minority = unlist(lapply(seed_distributions[selected_seed_states], function(df) df$per_minority))
)
# Remove precincts with missing or invalid data
census_blocks = census_blocks %>%
filter(!is.na(population), !is.na(per_minority), population > 0, per_minority >= 0, per_minority <= 1)
# Ensure per_minority values are within (0,1)
census_blocks$per_minority = pmin(pmax(census_blocks$per_minority, 0), 1)
#############################################
### Step 3: Adjust sampling probabilities ###
#############################################
# Set target mean minority percentage
if (state_type == 'low') {
target_per_min = 0.05   # 5%
} else if (state_type == 'medium') {
target_per_min = 0.175  # 17.5%
} else if (state_type == 'high') {
target_per_min = 0.325  # 32.5%
}
# Assign weights to precincts inversely proportional
# to their deviation from target minority percentage
# Makes precincts closer to target more likely to be sampled
census_blocks = census_blocks %>%
mutate(weight = 1 / (abs(per_minority - target_per_min) + 0.001)) # Small number to avoid division by zero
# Normalize weights
census_blocks$weight = census_blocks$weight / sum(census_blocks$weight)
############################################################
### Step 4: Sample precincts with adjusted probabilities ###
############################################################
# Initialize precincts data frame
precincts = data.frame(
precinct_id = numeric(),
population = numeric(),
per_minority = numeric()
)
# Initialize total population counter
N = 0
while (N < target_population) {
# Sample a batch of precincts with adjusted probabilities
sample_size = 1000  # Adjust as needed
# Sample row numbers from census block data weighted by weights calculated above
sampled_indices = sample(
x = 1:nrow(census_blocks),
size = sample_size,
replace = TRUE,
prob = census_blocks$weight
)
sampled_precincts = census_blocks[sampled_indices, ]
sampled_precincts$precinct_id = seq(nrow(precincts) + 1, nrow(precincts) + sample_size)
# Add sampled precincts to the precincts data frame
precincts = bind_rows(precincts, sampled_precincts)
# Update total population
N = sum(precincts$population)
}
# Truncate precincts to match the target population exactly
precincts = precincts %>%
mutate(cum_pop = cumsum(population)) %>%
filter(cum_pop <= target_population)
# Remove cumulative population column and rownames
precincts$cum_pop = NULL
rownames(precincts) = NULL
# Recalculate total population
N = sum(precincts$population)
# Calculate overall percent minority
overall_per_min = sum(precincts$population * precincts$per_minority) / sum(precincts$population)
cat('Overall percent minority:', round(overall_per_min * 100, 2), '%\n')
##########################################
### Step 5: Assign voters to precincts ###
##########################################
assign_voters_to_precincts = function(precinct_data) {
# # uncomment to debug
# precinct_data = precincts
# Calculate number of minority and majority voters per precinct
precinct_data = precinct_data %>%
mutate(
population = round(population),  # Ensure population is integer
num_min = round(population * per_minority),
num_maj = population - num_min
)
# Total number of voters
N = sum(precinct_data$population)
# Generate voter IDs sequentially
voter_id = 1:N
# Generate precinct IDs for each voter
precinct_ids = rep(precinct_data$precinct_id, times = precinct_data$population)
# Assign race to each voter
races = unlist(mapply(function(min_count, maj_count) {
c(rep(1, min_count), rep(0, maj_count))
}, precinct_data$num_min, precinct_data$num_maj, SIMPLIFY = FALSE))
# Determine voting probabilities based on method
if (voting_prob_assignment == 'constant') {
# Use constant probabilities
prob_minority_dem_vote_vec = rep(prob_minority_dem_vote, nrow(precinct_data))
prob_majority_dem_vote_vec = rep(prob_majority_dem_vote, nrow(precinct_data))
} else if (voting_prob_assignment == 'precinct') {
# Generate precinct-specific probabilities from normal distributions
precinct_data = precinct_data %>%
mutate(
prob_minority_dem_vote_precinct = rnorm(n(), mean = prob_minority_dem_vote, sd = sd_precinct_minority),
prob_majority_dem_vote_precinct = rnorm(n(), mean = prob_majority_dem_vote, sd = sd_precinct_majority)
)
# Ensure probabilities are within [0,1]
precinct_data$prob_minority_dem_vote_precinct = pmin(pmax(precinct_data$prob_minority_dem_vote_precinct, 0), 1)
precinct_data$prob_majority_dem_vote_precinct = pmin(pmax(precinct_data$prob_majority_dem_vote_precinct, 0), 1)
prob_minority_dem_vote_vec = precinct_data$prob_minority_dem_vote_precinct
prob_majority_dem_vote_vec = precinct_data$prob_majority_dem_vote_precinct
} else if (voting_prob_assignment == 'context') {
# Initialize vectors
prob_minority_dem_vote_vec = rep(prob_minority_dem_vote, nrow(precinct_data))
prob_majority_dem_vote_vec = rep(prob_majority_dem_vote, nrow(precinct_data))
# Identify precincts with high and low minority fractions
high_minority = precinct_data$per_minority > context_threshold
low_minority = precinct_data$per_minority < context_threshold
# Apply positive shocks to majority voters in high minority precincts
if (any(high_minority)) {
# Generate random indicators for applying shocks
apply_shock_pos = rbinom(sum(high_minority), 1, prob_shock_pos)
# Apply shocks where indicator is 1
prob_majority_dem_vote_vec[high_minority] = prob_majority_dem_vote_vec[high_minority] +
apply_shock_pos * shock_positive
}
# Apply negative shocks to majority voters in low minority precincts
if (any(low_minority)) {
# Generate random indicators for applying shocks
apply_shock_neg = rbinom(sum(low_minority), 1, prob_shock_neg)
# Apply shocks where indicator is 1
prob_majority_dem_vote_vec[low_minority] = prob_majority_dem_vote_vec[low_minority] -
apply_shock_neg * shock_negative
}
# Ensure probabilities are within [0,1]
prob_majority_dem_vote_vec = pmin(pmax(prob_majority_dem_vote_vec, 0), 1)
}
# Add random noise to each voter's probability
# Create vectors of base probabilities for each voter
probabilities = unlist(mapply(function(min_count, maj_count, p_min, p_maj) {
c(rep(p_min, min_count), rep(p_maj, maj_count))
}, precinct_data$num_min, precinct_data$num_maj, prob_minority_dem_vote_vec, prob_majority_dem_vote_vec, SIMPLIFY = FALSE))
# Generate random noise for each voter
noise = rnorm(length(probabilities), mean = 0, sd = sd_ind_noise)
# Adjust probabilities and ensure they remain within [0,1]
individual_probabilities = pmin(pmax(probabilities + noise, 0), 1)
# Generate votes based on individual probabilities
votes = rbinom(length(individual_probabilities), 1, prob = individual_probabilities)
# Assemble the voter data frame
electorate = data.frame(
voter_id = voter_id,
precinct_id = precinct_ids,
race = races,
vote = votes
)
return(electorate)
}
###############################
### Step 6: Generate voters ###
###############################
electorate = assign_voters_to_precincts(precincts)
precincts = electorate %>%
group_by(precinct_id) %>%
summarise(population = n(),
per_minority = sum(race) / population,
dem_voteshare = sum(vote) / population)
# Function returns:
# Precinct-level data
# Individual-level data
# List of parameters used to seed the simulation for a state
return(list(precinct_data = precincts,
voter_data = electorate,
seed_parameters = list(target_population = target_population,
state_type = state_type,
prob_minority_dem_vote = prob_minority_dem_vote,
prob_majority_dem_vote = prob_majority_dem_vote,
voting_prob_assignment = voting_prob_assignment,
sd_ind_noise = sd_ind_noise,
sd_precinct_minority = sd_precinct_minority,
sd_precinct_majority = sd_precinct_majority,
context_threshold = context_threshold,
prob_shock_pos = prob_shock_pos,
shock_positive = shock_positive,
prob_shock_neg = prob_shock_neg,
shock_negative = shock_negative)))
}
# Simulate a few states for EI/ER
N_states = 1
populations = 3000000
state_types = rep(c('low', 'high'), 1)
# Simulate a few states for EI/ER
N_states = 2
populations = round(runif(N_states, 500000, 3000000))
state_types = rep(c('low', 'high'), 2)
state_types = rep(c('low', 'high'), 1)
min_probs = rnorm(N_states, 0.8, 0.05)
maj_probs = rnorm(N_states, 0.45, 0.2)
#voting_prob_assignments = sample(c('constant', 'precinct', 'context'), N_states, replace = TRUE)
voting_prob_assignments = rep("constant",N_states)
thresh = runif(N_states, min = 0.15, 0.5)
prob_pos = rnorm(N_states, 0.5, 0.2)
pos_shocks = runif(N_states, 0.05, 0.2)
prob_neg = rnorm(N_states, 0.5, 0.1)
neg_shocks = runif(N_states, 0.075, 0.2)
